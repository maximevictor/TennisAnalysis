{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMLD workshop by L2F–Learn to Forecast\n",
    "\n",
    "Welcome to the \"Machine Learning Competition\" workshop at AMLD 2019, organized by L2F–Learn to Forecast!\n",
    "\n",
    "We will work with a dataset of tennis matches, with a shot-by-shot description of each point. We will focus on the two Swiss tennis stars: Roger Federer and Stanislas Wawrinka. \n",
    "\n",
    "The goals of this workshop are two-fold:\n",
    "\n",
    "+ Predict the outcome (win/lose) of a rally (sequence of shots).\n",
    "+ Develop a coaching strategy to help Roger and Stan improve. \n",
    "\n",
    "This notebook contains a rudimentary analysis to help you get started. Good luck :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from Jeff Sackmann's GitHub\n",
    "\n",
    "(See Excel sheet 'MatchChart 0.2.0' for full description)\n",
    "\n",
    "Each row is one point.\n",
    "Volunteers manually input the rally in the '1st' or '2nd' column, depending on wether it's a first or second serve (the other features, like the score, are automatically populated).\n",
    "\n",
    "Numbers are used to indicate direction and depth, while letters are used to specific shot types (e.g. 'f' stands for 'forehand') and error types ('n' stands for 'net').  \n",
    "\n",
    "A few symbols are used for other purposes, such as types of errors (e.g. '@' means 'unforced error' and '+' indicates an approach shot).\n",
    "\n",
    "See README for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'match_id', 'Pt', 'Set1', 'Set2', 'Gm1', 'Gm2', 'Pts',\n",
       "       'Gm#', 'TbSet', 'TB?', 'TBpt', 'Svr', 'Ret', 'Serving', '1st', '2nd',\n",
       "       'Notes', '1stNoLet', '2ndNoLet', '1stSV', '2ndSV', '1stNoSV', '2ndNoSV',\n",
       "       '1stIn', '2ndIn', 'isRally1st', 'isRally2nd', 'Sv1', 'Sv2', 'isAce',\n",
       "       'isUnret', 'isRallyWinner', 'isForced', 'isUnforced', 'isDouble',\n",
       "       'rallyNoSpec', 'rallyNoError', 'rallyNoDirection', 'rallyLen',\n",
       "       'PtWinner', 'isSvrWinner', 'PtsAfter', 'GmW', 'Gm1.1', 'Gm2.1', 'SetW',\n",
       "       'Set1.1', 'Set2.1', 'RevTB', 'TBrev', 'rallyCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('charting-m-points_clean.csv',\n",
    "                 encoding='latin1',\n",
    "                 dtype={'Gm#': str, 'TB?': str, 'rallyCount': str})   # Specify dtype for some mixed columns)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st</th>\n",
       "      <th>2nd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6*</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4n</td>\n",
       "      <td>6f27b2b2b3b3b2b3b3b3w@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4f38b+3s2v1*</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6f37b+3s2h1w#</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4r3w#</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1st                     2nd\n",
       "0             6*                     NaN\n",
       "1             4n  6f27b2b2b3b3b2b3b3b3w@\n",
       "2   4f38b+3s2v1*                     NaN\n",
       "3  6f37b+3s2h1w#                     NaN\n",
       "4          4r3w#                     NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of sequences of shots\n",
    "\n",
    "df[['1st', '2nd']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second match summary dataset which might be of use. This is a cleaned-up version of the file in https://github.com/JeffSackmann/tennis_MatchChartingProject/blob/master/charting-m-matches.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Player 2</th>\n",
       "      <th>Pl 1 hand</th>\n",
       "      <th>Pl 2 hand</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Round</th>\n",
       "      <th>Time</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Umpire</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Final TB?</th>\n",
       "      <th>Charted by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20181104-M-Paris_Masters-F-Novak_Djokovic-Kare...</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>Karen Khachanov</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>20181104</td>\n",
       "      <td>Paris Masters</td>\n",
       "      <td>F</td>\n",
       "      <td>3pm</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>Cedric Mourier</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Edo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20181103-M-Paris_Masters-SF-Novak_Djokovic-Rog...</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>Roger Federer</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>20181103</td>\n",
       "      <td>Paris Masters</td>\n",
       "      <td>SF</td>\n",
       "      <td>4:00 PM</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Carlos Bernardes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Palaver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20181101-M-Paris_Masters-R16-Dominic_Thiem-Bor...</td>\n",
       "      <td>Dominic Thiem</td>\n",
       "      <td>Borna Coric</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>20181101</td>\n",
       "      <td>Paris Masters</td>\n",
       "      <td>R16</td>\n",
       "      <td>4:35 PM</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Nacho Forcadell</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ChapelHeel66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20181101-M-Paris_Masters-R16-Diego_Sebastian_S...</td>\n",
       "      <td>Diego Sebastian Schwartzman</td>\n",
       "      <td>Alexander Zverev</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>20181101</td>\n",
       "      <td>Paris Masters</td>\n",
       "      <td>R16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Carlos Bernardes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Isaac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20181031-M-Paris_Masters-R32-Daniil_Medvedev-B...</td>\n",
       "      <td>Daniil Medvedev</td>\n",
       "      <td>Borna Coric</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>20181031</td>\n",
       "      <td>Paris Masters</td>\n",
       "      <td>R32</td>\n",
       "      <td>11:30 AM</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Nacho Forcadell</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ChapelHeel66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            match_id  \\\n",
       "0  20181104-M-Paris_Masters-F-Novak_Djokovic-Kare...   \n",
       "1  20181103-M-Paris_Masters-SF-Novak_Djokovic-Rog...   \n",
       "2  20181101-M-Paris_Masters-R16-Dominic_Thiem-Bor...   \n",
       "3  20181101-M-Paris_Masters-R16-Diego_Sebastian_S...   \n",
       "4  20181031-M-Paris_Masters-R32-Daniil_Medvedev-B...   \n",
       "\n",
       "                      Player 1          Player 2 Pl 1 hand Pl 2 hand Gender  \\\n",
       "0               Novak Djokovic   Karen Khachanov         R         R      M   \n",
       "1               Novak Djokovic     Roger Federer         R         R      M   \n",
       "2                Dominic Thiem       Borna Coric         R         R      M   \n",
       "3  Diego Sebastian Schwartzman  Alexander Zverev         R         R      M   \n",
       "4              Daniil Medvedev       Borna Coric         R         R      M   \n",
       "\n",
       "       Date     Tournament Round      Time   Court Surface            Umpire  \\\n",
       "0  20181104  Paris Masters     F       3pm  Centre  Carpet    Cedric Mourier   \n",
       "1  20181103  Paris Masters    SF   4:00 PM  Centre    Hard  Carlos Bernardes   \n",
       "2  20181101  Paris Masters   R16   4:35 PM  Centre    Hard   Nacho Forcadell   \n",
       "3  20181101  Paris Masters   R16       NaN     NaN    Hard  Carlos Bernardes   \n",
       "4  20181031  Paris Masters   R32  11:30 AM  Centre    Hard   Nacho Forcadell   \n",
       "\n",
       "   Best of Final TB?    Charted by  \n",
       "0        3         1           Edo  \n",
       "1        3         1       Palaver  \n",
       "2        3         1  ChapelHeel66  \n",
       "3        3         1         Isaac  \n",
       "4        3         1  ChapelHeel66  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match = pd.read_csv('charting-m-matches_clean.csv')\n",
    "assert set(df.match_id).intersection(set(df_match.match_id)) == set(df.match_id)  # Checking that all match ids in the point-by-point dataset are accounted for in the summary dataset\n",
    "df_match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by spliting the *match_id* strings into separate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Date','Sex','Tournament','Stage','Player1','Player2']] = df['match_id'].str.split('-', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split sequences in columns *1st* or *2nd* into a rally (which includes the serve) and an outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rally_outcome(sequence):\n",
    "    # Special situations\n",
    "    if pd.isnull(sequence):\n",
    "        return np.nan, np.nan\n",
    "    if sequence in {'S', 'Q'}:\n",
    "        return '0', '*'\n",
    "    if sequence in {'R', 'P', 'V'}:\n",
    "        return '0', '@'\n",
    "    # \"Regular\" rally endings\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i] in ['n','w','d','x','g','e','!','*','#','@']:\n",
    "            return sequence[:i], sequence[i:]\n",
    "    return None, None\n",
    "\n",
    "df['1stRally'], df['1stOutcome'] = zip(*df['1st'].map(rally_outcome))\n",
    "df['2ndRally'], df['2ndOutcome'] = zip(*df['2nd'].map(rally_outcome))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final rallies and outcomes are selected from the first serve if there was no second serve, and from the second otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Null2ndRally'] = df['2ndRally'].isnull()\n",
    "df['Rally'] = df['1stRally'].where(df['Null2ndRally'], other=df['2ndRally'])\n",
    "df['Outcome'] = df['1stOutcome'].where(df['Null2ndRally'], other=df['2ndOutcome'])\n",
    "df['Null2ndRally'] = df['Null2ndRally'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['*', 'w@', 'w#', 'd#', 'd@', 'n#', 'n@', '#', 'n', 'w', 'x@', 'x#',\n",
       "       '@', '!@', 'd', '!w', 'x', '!#', 'g', '!d@', 'n!@', '#n', '!d#',\n",
       "       'n3@', '!2d#', 'e#', 'e@', 'd2#', 'w!@', 'd*', 'n2#', 'x1@', 'n*',\n",
       "       '!', 'd2@', 'd@+', '!w@', '!2d@', 'wf#', 'w3', 'n#3', 'wo1*', 'd2',\n",
       "       'n@#', 'dw@', '*1', '*@', '*n#', 'e', 'n2@', 'nw@', 'nv#', 'd3#',\n",
       "       'w*', 'w-#', '!3*', '!w#', 'wd', 'nn#', 'd@!', '*7', '!x@', 'd!#',\n",
       "       'ww#', '!3d@', 'dn#', '!1d@', '!1x@', '!3w#', '!3x@', '!3w@',\n",
       "       '!1w@', 'w;', '#!', 'wy1*', '!1w#', '!1d#', 'd1@', '!3d#', 'w1@',\n",
       "       '!n#', '!2*', '!1x#', 'd!@', '!f1*', 'w;@', '!n@', 'x1*', '!3@',\n",
       "       '!s@', 'nx', 'n1@', '@n', '!1@', 'd!*', 'n1#', 'x2@', 'n17*',\n",
       "       'ww@', 'n-@', 'w#@', 'n3n#', '!*', 'd3b1f1#', '!3n@', 'd+@',\n",
       "       'wb1*', 'n3#', 'nd@', 'wd@', 'd2d', 'x#@', 'xs#', 'w-@', 'w@*',\n",
       "       'd-@', 'n+@', 'x;', 'n-#', '!x#', '!2@', 'x*', 'dx@', 'x2n#',\n",
       "       'ebf*', 'dn@', 'n+', '!38*', 'wx#', 'wx'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Outcome'].unique() #####  STILL TYPOS AFTER CLEANING?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the available list of characters denoting shot types, we can split rallies into string of shots separated by empty spaces. This will be useful when applying vectorization techniques later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_types = ['f','b','r','s','v','z','o','p','u','y','l','m','h','i','j','k','t','q']\n",
    "\n",
    "def split_shots(rally):\n",
    "    # Split on all shot types\n",
    "    list_chars = re.findall('([{0}][^{1}]*|\\A[^{1}]*)'.\n",
    "                            format('|'.join(shot_types), ''.join(shot_types)), rally)\n",
    "    return ' '.join(list_chars)\n",
    "\n",
    "df['Shots'] = df['Rally'].apply(split_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Player1</th>\n",
       "      <th>Player2</th>\n",
       "      <th>Null2ndRally</th>\n",
       "      <th>Rally</th>\n",
       "      <th>Shots</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20181104</td>\n",
       "      <td>M</td>\n",
       "      <td>Paris_Masters</td>\n",
       "      <td>F</td>\n",
       "      <td>Novak_Djokovic</td>\n",
       "      <td>Karen_Khachanov</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20181104</td>\n",
       "      <td>M</td>\n",
       "      <td>Paris_Masters</td>\n",
       "      <td>F</td>\n",
       "      <td>Novak_Djokovic</td>\n",
       "      <td>Karen_Khachanov</td>\n",
       "      <td>0</td>\n",
       "      <td>6f27b2b2b3b3b2b3b3b3</td>\n",
       "      <td>6 f27 b2 b2 b3 b3 b2 b3 b3 b3</td>\n",
       "      <td>w@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20181104</td>\n",
       "      <td>M</td>\n",
       "      <td>Paris_Masters</td>\n",
       "      <td>F</td>\n",
       "      <td>Novak_Djokovic</td>\n",
       "      <td>Karen_Khachanov</td>\n",
       "      <td>1</td>\n",
       "      <td>4f38b+3s2v1</td>\n",
       "      <td>4 f38 b+3 s2 v1</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20181104</td>\n",
       "      <td>M</td>\n",
       "      <td>Paris_Masters</td>\n",
       "      <td>F</td>\n",
       "      <td>Novak_Djokovic</td>\n",
       "      <td>Karen_Khachanov</td>\n",
       "      <td>1</td>\n",
       "      <td>6f37b+3s2h1</td>\n",
       "      <td>6 f37 b+3 s2 h1</td>\n",
       "      <td>w#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20181104</td>\n",
       "      <td>M</td>\n",
       "      <td>Paris_Masters</td>\n",
       "      <td>F</td>\n",
       "      <td>Novak_Djokovic</td>\n",
       "      <td>Karen_Khachanov</td>\n",
       "      <td>1</td>\n",
       "      <td>4r3</td>\n",
       "      <td>4 r3</td>\n",
       "      <td>w#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date Sex     Tournament Stage         Player1          Player2  \\\n",
       "0  20181104   M  Paris_Masters     F  Novak_Djokovic  Karen_Khachanov   \n",
       "1  20181104   M  Paris_Masters     F  Novak_Djokovic  Karen_Khachanov   \n",
       "2  20181104   M  Paris_Masters     F  Novak_Djokovic  Karen_Khachanov   \n",
       "3  20181104   M  Paris_Masters     F  Novak_Djokovic  Karen_Khachanov   \n",
       "4  20181104   M  Paris_Masters     F  Novak_Djokovic  Karen_Khachanov   \n",
       "\n",
       "   Null2ndRally                 Rally                          Shots Outcome  \n",
       "0             1                     6                              6       *  \n",
       "1             0  6f27b2b2b3b3b2b3b3b3  6 f27 b2 b2 b3 b3 b2 b3 b3 b3      w@  \n",
       "2             1           4f38b+3s2v1                4 f38 b+3 s2 v1       *  \n",
       "3             1           6f37b+3s2h1                6 f37 b+3 s2 h1      w#  \n",
       "4             1                   4r3                           4 r3      w#  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Date','Sex','Tournament','Stage','Player1','Player2','Null2ndRally', 'Rally','Shots','Outcome']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swiss players\n",
    "\n",
    "Focus on Roger Federer and Stanislas Wawrinka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points played by Roger_Federer: 59492\n"
     ]
    }
   ],
   "source": [
    "# Select all points played by a given player\n",
    "\n",
    "player_name = 'Roger_Federer'   # or 'Stanislas_Wawrinka'\n",
    "df_player = df[(df['Player1'] == player_name) | (df['Player2'] == player_name)].copy()\n",
    "print('Number of points played by {0}: {1}'.format(player_name, len(df_player)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features: - 'PlayerNum': {1: player_name equals Player1, 2: player_name equals Player2};\n",
    "#               - Winner': {0: player loses, 1: player wins};\n",
    "#               - 'Server': {0: player returns, 1: player serves};\n",
    "\n",
    "df_player['PlayerNum'] = df_player['Player1'].apply(lambda name: 1 if (name == player_name) else 2)\n",
    "df_player['Winner'] = df_player[['PtWinner', 'PlayerNum']].apply(lambda lst: int(lst[0] == lst[1]), axis=1)\n",
    "df_player['Server'] = df_player[['Svr', 'PlayerNum']].apply(lambda lst: int(lst[0] == lst[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split rally into shots by selected player (Shots1) and shots by opponent (Shots0)\n",
    "def split_odd_even_shots(x):\n",
    "    if x[0] == 1:\n",
    "        shots1, shots0 = x[1].split(' ')[0::2], x[1].split(' ')[1::2]\n",
    "    else:\n",
    "        shots1, shots0 = x[1].split(' ')[1::2], x[1].split(' ')[0::2]\n",
    "    return ' '.join(shots1), ' '.join(shots0)\n",
    "\n",
    "df_player['Shots1'], df_player['Shots0'] = zip(*df_player[['Server', 'Shots']].apply(split_odd_even_shots, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerNum</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Server</th>\n",
       "      <th>Shots1</th>\n",
       "      <th>Shots0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>s3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>f28</td>\n",
       "      <td>6 f3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f29 s1 f1 s3 f1</td>\n",
       "      <td>4 b2 f1 f3 f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>s38 f;1</td>\n",
       "      <td>4 b1 f3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>f17 s3 f1 f3</td>\n",
       "      <td>4 f3 b1 r1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PlayerNum  Winner  Server           Shots1         Shots0\n",
       "137          2       0       0               s3              5\n",
       "138          2       1       0              f28           6 f3\n",
       "139          2       0       0  f29 s1 f1 s3 f1  4 b2 f1 f3 f1\n",
       "140          2       0       0          s38 f;1        4 b1 f3\n",
       "141          2       1       0     f17 s3 f1 f3     4 f3 b1 r1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_player[['PlayerNum', 'Winner', 'Server', 'Shots1', 'Shots0']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict rally outcome\n",
    "The goal of this part is to build a model that can predict the outcome of a rally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roger_Federer's winning rate: 0.529\n"
     ]
    }
   ],
   "source": [
    "# Target variable to predict {0: lose, 1: win}\n",
    "\n",
    "y = df_player['Winner'].values\n",
    "print(\"{}'s winning rate: {:0.3f}\".format(player_name, y.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model: server wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roger_Federer's winning rate when serving: 0.681 \n",
      "Roger_Federer's losing rate when returning: 0.616\n"
     ]
    }
   ],
   "source": [
    "win_ser = df_player[df_player['Server'] == 1]['Winner'].mean()\n",
    "win_ret = df_player[df_player['Server'] == 0]['Winner'].mean()\n",
    "print(\"{}'s winning rate when serving: {:0.3f}\".format(player_name, win_ser), \n",
    "      \"\\n{}'s losing rate when returning: {:0.3f}\".format(player_name, 1 - win_ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.647\n"
     ]
    }
   ],
   "source": [
    "######## CORRECT METRIC???? BALANCE CLASSES!?!?!?!?!?!\n",
    "\n",
    "baseline_acc = (len(df_player[df_player['Server'] == 1]) * win_ser \\\n",
    "                + len(df_player[df_player['Server'] == 0]) * (1-win_ret)) / (len(df_player))\n",
    "print('Baseline accuracy: {:0.3f}'.format(baseline_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-by-character approach\n",
    "Count occurences of shot types, direction, position, etc. (e.g. 'f', 'b', '5', '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of length 34 :\n",
      " ['+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ';', '=', '^', 'b', 'c', 'f', 'h', 'i', 'j', 'k', 'l', 'm', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# Create a CountVectorizer object\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='char', max_df=1.0, min_df=2)\n",
    "count_vect.fit(df_player['Rally'])\n",
    "# Vocabulary\n",
    "print('Vocabulary of length {} :\\n'.format(len(count_vect.get_feature_names())), \n",
    "      count_vect.get_feature_names()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in place, we can immediately transform rallies into vectors and begin creating our feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59492, 34)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_r = count_vect.transform(df_player['Rally']).toarray()  # Without .toarray(), we would get a sparse matrix representation\n",
    "X_r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional features from the original dataframe can also be incorporated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59492, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_features_names = ['Server', 'Null2ndRally']\n",
    "extra_features = df_player[extra_features_names].values\n",
    "extra_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59492, 36)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.hstack((X_r, extra_features))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6465710443747199"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regresssion \n",
    "clf = LogisticRegression(random_state=0, solver='liblinear', \n",
    "                         penalty='l1', C=1.0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most important features\n",
    "feature_list = count_vect.get_feature_names() + extra_features_names\n",
    "feature_importance = pd.DataFrame(\n",
    "    {'Feature': feature_list,\n",
    "     'Importance': clf.coef_.tolist()[0]\n",
    "    })\n",
    "feat_imp = feature_importance.sort_values(by=['Importance'], ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Server</td>\n",
       "      <td>1.234619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>j</td>\n",
       "      <td>0.281257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>m</td>\n",
       "      <td>0.172116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+</td>\n",
       "      <td>0.157695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>t</td>\n",
       "      <td>0.148753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>l</td>\n",
       "      <td>-0.091796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>=</td>\n",
       "      <td>-0.143601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>p</td>\n",
       "      <td>-0.194629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>k</td>\n",
       "      <td>-0.385040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>q</td>\n",
       "      <td>-0.545885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Importance\n",
       "34  Server    1.234619\n",
       "20       j    0.281257\n",
       "23       m    0.172116\n",
       "0        +    0.157695\n",
       "29       t    0.148753\n",
       "22       l   -0.091796\n",
       "13       =   -0.143601\n",
       "25       p   -0.194629\n",
       "21       k   -0.385040\n",
       "26       q   -0.545885"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.iloc[np.r_[0:5, -5:0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umbertolupo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/umbertolupo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/umbertolupo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: 0.647 (+/-0.025)\n",
      "Naive Bayes: 0.565 (+/-0.016)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umbertolupo/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/umbertolupo/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/umbertolupo/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector: 0.647 (+/-0.024)\n",
      "Decision Tree: 0.724 (+/-0.025)\n",
      "Random Forest: 0.730 (+/-0.026)\n"
     ]
    }
   ],
   "source": [
    "# Compare classifiers\n",
    "lr = LogisticRegression()\n",
    "mnb = MultinomialNB()\n",
    "svc = LinearSVC()\n",
    "dt = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "for clf, name in [(lr, 'Logistic'),\n",
    "                  (mnb, 'Naive Bayes'),\n",
    "                  (svc, 'Support Vector'),\n",
    "                  (dt, 'Decision Tree'),\n",
    "                  (rfc, 'Random Forest')]:\n",
    "    scores = cross_val_score(clf, X, y, cv=3)\n",
    "    print(\"{}: {:0.3f} (+/-{:0.3f})\".format(name, scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot-by-shot approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of length 105:\n",
      " ['0', '4', '4+', '5', '5+', '6', '6+', 'b', 'b+1', 'b+2', 'b+3', 'b-1', 'b-3', 'b1', 'b17', 'b18', 'b19', 'b2', 'b27', 'b28', 'b29', 'b3', 'b37', 'b38', 'b39', 'b;2', 'b;3', 'c4', 'c5', 'c6', 'f', 'f+1', 'f+2', 'f+3', 'f-1', 'f-3', 'f1', 'f17', 'f18', 'f19', 'f2', 'f27', 'f28', 'f29', 'f3', 'f37', 'f38', 'f39', 'f;1', 'f;2', 'f;3', 'h2', 'h3', 'i1', 'i2', 'i3', 'j1', 'j3', 'l1', 'l2', 'l3', 'm', 'm1', 'm2', 'm3', 'o1', 'o2', 'o3', 'r', 'r1', 'r2', 'r27', 'r28', 'r29', 'r3', 's', 's+1', 's+2', 's+3', 's1', 's17', 's18', 's19', 's2', 's27', 's28', 's29', 's3', 's37', 's38', 's39', 'u+3', 'u1', 'u3', 'v', 'v1', 'v2', 'v3', 'y+1', 'y1', 'y3', 'z', 'z1', 'z2', 'z3']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False, analyzer='word', token_pattern='\\S+', max_df=1.0, min_df=100)\n",
    "vectorizer.fit(df_player['Shots'])\n",
    "# Vocabulary\n",
    "print('Vocabulary of length {}:\\n'.format(len(vectorizer.get_feature_names())), \n",
    "      vectorizer.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59492, 210)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = vectorizer.transform(df_player['Shots1']).toarray()\n",
    "X0 = vectorizer.transform(df_player['Shots0']).toarray()\n",
    "X_r = np.hstack((X1, X0))\n",
    "X_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((X_r, extra_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7801994621246078"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regresssion \n",
    "clf = LogisticRegression(random_state=0, solver='liblinear', \n",
    "                         penalty='l1', C=1.0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>v_0</td>\n",
       "      <td>5.751407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>r_0</td>\n",
       "      <td>5.044248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>s_0</td>\n",
       "      <td>3.820395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>z_0</td>\n",
       "      <td>3.405452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>h2_0</td>\n",
       "      <td>3.132924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b_1</td>\n",
       "      <td>-2.988094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>v_1</td>\n",
       "      <td>-3.396663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>f_1</td>\n",
       "      <td>-3.420437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>r_1</td>\n",
       "      <td>-3.780777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>z_1</td>\n",
       "      <td>-4.060957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  Importance\n",
       "199     v_0    5.751407\n",
       "173     r_0    5.044248\n",
       "180     s_0    3.820395\n",
       "206     z_0    3.405452\n",
       "156    h2_0    3.132924\n",
       "7       b_1   -2.988094\n",
       "94      v_1   -3.396663\n",
       "30      f_1   -3.420437\n",
       "68      r_1   -3.780777\n",
       "101     z_1   -4.060957"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most important features\n",
    "vocab = vectorizer.get_feature_names()\n",
    "feature_list = [w + '_1' for w in vocab] + [w + '_0' for w in vocab] + extra_features_names\n",
    "feature_importance = pd.DataFrame(\n",
    "    {'Feature': feature_list,\n",
    "     'Importance': clf.coef_.tolist()[0]\n",
    "    })\n",
    "feat_imp = feature_importance.sort_values(by=['Importance'], ascending=False) \n",
    "feat_imp.iloc[np.r_[0:5, -5:0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other models can be defined and hyperparameter-tuned efficiently by using a grid search approach within an sklearn pipeline. Here is an example using a random forest classifier and a cross-validation routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_model = RandomForestClassifier()\n",
    "param_grid = {'randomforestclassifier__n_estimators': range(5, 151, 10)}\n",
    "\n",
    "clf = make_pipeline(regr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = GridSearchCV(clf, param_grid, cv=10)  # Pass 'verbose=10' to have detailed progress information printed on screen\n",
    "classifier_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier_model.best_estimator_.predict(X_test)\n",
    "label_validation = y_test\n",
    "accuracy_score(predictions, label_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-dimensional Convolutional Neural Network (CNN)\n",
    "\n",
    "See https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPool1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a CNN on time-UNordered features representing the vectorized sequences of shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(\n",
    "    layer_dims=[64, 32],\n",
    "    kernel_sizes=[4, 3],\n",
    "    pool_sizes=[2],\n",
    "    activation_conv='relu',\n",
    "    activation_dense='sigmoid',\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    "):\n",
    "    \n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add model hidden layers\n",
    "    model.add(Conv1D(layer_dims[0], kernel_size=kernel_sizes[0], activation=activation_conv))\n",
    "    model.add(Conv1D(layer_dims[1], kernel_size=kernel_sizes[1], activation=activation_conv))\n",
    "    model.add(MaxPool1D(pool_size=pool_sizes[0]))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation=activation_dense))\n",
    "    \n",
    "    # Compile model using accuracy to measure model performance\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape features to input them to the 1d CNN\n",
    "unord_rally_features = np.reshape(X_r, (-1,105,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "train_x, test_x, train_y, test_y = train_test_split(unord_rally_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44619 samples, validate on 14873 samples\n",
      "Epoch 1/5\n",
      "44619/44619 [==============================] - 13s 293us/step - loss: 0.5547 - acc: 0.7306 - val_loss: 0.5158 - val_acc: 0.7557\n",
      "Epoch 2/5\n",
      "44619/44619 [==============================] - 12s 267us/step - loss: 0.5135 - acc: 0.7573 - val_loss: 0.5040 - val_acc: 0.7631\n",
      "Epoch 3/5\n",
      "44619/44619 [==============================] - 17s 375us/step - loss: 0.5039 - acc: 0.7622 - val_loss: 0.5115 - val_acc: 0.7588\n",
      "Epoch 4/5\n",
      "44619/44619 [==============================] - 10s 234us/step - loss: 0.4999 - acc: 0.7664 - val_loss: 0.4995 - val_acc: 0.7649\n",
      "Epoch 5/5\n",
      "44619/44619 [==============================] - 13s 291us/step - loss: 0.4969 - acc: 0.7665 - val_loss: 0.4966 - val_acc: 0.7740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2d014a58>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and train the model\n",
    "model = cnn_model()\n",
    "model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the distribution of rally lengths. What's the maximum rally length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist((df_player['Shots'].apply(lambda x: x.split()).apply(len).values))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, our features do not capture the order in which shots occurred. But this is clearly useful information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ord_shots = []\n",
    "\n",
    "for rl in df_player[['Shots1', 'Shots0', 'Server']].values:\n",
    "        # Adding a null feature vector to make the chosen player features always be in the first position\n",
    "        if rl[2] == 0:\n",
    "            rl[0] = 'K ' + rl[0]\n",
    "            \n",
    "        rl1split = rl[0].split()\n",
    "        rl2split = rl[1].split()\n",
    "        \n",
    "        # Padding the sequences of shots\n",
    "        rl1split += [' K']*(20 - len(rl1split))\n",
    "        rl2split += [' K']*(20 - len(rl2split))\n",
    "        \n",
    "        # Merging the shots of the player and the opponent\n",
    "        features = np.hstack((vectorizer.transform(rl1split).toarray(), vectorizer.transform(rl2split).toarray()))\n",
    "        player_ord_shots.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 210)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_ord_shots[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in a position to train a CNN on **ordered** sequences of shots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44619 samples, validate on 14873 samples\n",
      "Epoch 1/5\n",
      "44619/44619 [==============================] - 11s 240us/step - loss: 0.4823 - acc: 0.7677 - val_loss: 0.4277 - val_acc: 0.8027\n",
      "Epoch 2/5\n",
      "44619/44619 [==============================] - 10s 235us/step - loss: 0.4041 - acc: 0.8135 - val_loss: 0.4059 - val_acc: 0.8127\n",
      "Epoch 3/5\n",
      "44619/44619 [==============================] - 11s 247us/step - loss: 0.3882 - acc: 0.8208 - val_loss: 0.4030 - val_acc: 0.8164\n",
      "Epoch 4/5\n",
      "44619/44619 [==============================] - 10s 226us/step - loss: 0.3758 - acc: 0.8279 - val_loss: 0.4064 - val_acc: 0.8160\n",
      "Epoch 5/5\n",
      "44619/44619 [==============================] - 11s 247us/step - loss: 0.3638 - acc: 0.8333 - val_loss: 0.4195 - val_acc: 0.8107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6895b978>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_shape = player_ord_shots[0].shape\n",
    "\n",
    "# Reshape features to input them to the 1d CNN\n",
    "ord_features = np.reshape(player_ord_shots, (-1, features_shape[0], features_shape[1]))\n",
    "\n",
    "# Train-test split\n",
    "train_x, test_x, train_y, test_y = train_test_split(ord_features, y)\n",
    "\n",
    "# Create and train the model\n",
    "model = cnn_model()\n",
    "model.fit(train_x, train_y, validation_data = (test_x, test_y), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the score with the ground truth labels\n",
    "true_prediction_t = []\n",
    "true_prediction_f = []\n",
    "\n",
    "for n in range(len(test_x)):\n",
    "    score = model.predict(np.asarray([test_x[n]]))[0][0]\n",
    "    if test_y[n] == 1:    \n",
    "        true_prediction_t.append(score)\n",
    "    else:\n",
    "        true_prediction_f.append(score)\n",
    "        \n",
    "\n",
    "plt.hist(true_prediction_t, alpha = 0.5)\n",
    "plt.hist(true_prediction_f, alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent approach LSTM\n",
    "\n",
    "LSTM are normally used to predict the future behaviour of a time series or to predict the next word in an unfinished sentence. These methods train on the **past** and aim to give an estimate of the **near future**.\n",
    "\n",
    "In our case, the LSTM takes as input the ordered sequence of shots and tries to predict the outcome of the point: the **past** is the sequence of shots and the **near future** is the outcome of the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM: each entry mush be in the form (time samples, features)\n",
    "\n",
    "player_ord_shots_lstm = []\n",
    "\n",
    "for rl in df_player['Shots1', 'Shots0', 'Server']].values:\n",
    "        #adding a null feature vector to make the chosen player features always be in position one\n",
    "        if rl[2] == 1:\n",
    "            rl[1] = rl[1] + ' K'\n",
    "            \n",
    "        rl1split = rl[0].split()\n",
    "        rl2split = rl[1].split()\n",
    "        #padding the sequences of shots\n",
    "        rl1split = ['K ']*(20 - len(rl1split)) + rl1split\n",
    "        rl2split = ['K ']*(20 - len(rl2split)) + rl2split\n",
    "        #merging the shots of the player and the opponent\n",
    "        features = np.hstack((vectorizer.transform(rl1split).toarray(),vectorizer.transform(rl2split).toarray()))\n",
    "        player_ord_shots_lstm.append(features)\n",
    "            \n",
    "player_ord_shots_lstm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the LSTM network to ordered features\n",
    "\n",
    "features_shape = player_ord_shots_lstm[0].shape\n",
    "\n",
    "\n",
    "# Create model\n",
    "model1 = Sequential()\n",
    "# Add model hidden layers\n",
    "model1.add(LSTM(5, input_shape = features_shape, return_sequences = True))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(20, activation = \"relu\"))\n",
    "model1.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "# Compile model using accuracy to measure model performance\n",
    "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "ord_features = np.reshape(player_ord_shots_lstm,(-1, features_shape[0], features_shape[1]))\n",
    "\n",
    "# Train-test split\n",
    "train_x, test_x, train_y, test_y = train_test_split(ord_features, ord_labels)\n",
    "\n",
    "# Train the model\n",
    "model1.fit(train_x, train_y, validation_data = (test_x, test_y), epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the score with the ground truth labels\n",
    "true_prediction_t = []\n",
    "true_prediction_f = []\n",
    "\n",
    "for n in range(len(test_x)):\n",
    "    score = model1.predict(np.asarray([test_x[n]]))[0][0]\n",
    "    if test_y[n] == 1:    \n",
    "        true_prediction_t.append(score)\n",
    "    else:\n",
    "        true_prediction_f.append(score)\n",
    "        \n",
    "\n",
    "plt.hist(true_prediction_t, alpha = 0.5)\n",
    "plt.hist(true_prediction_f, alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coaching strategies\n",
    "\n",
    "Come up with a data-based strategy to give improving advices to Federer and Wawrinka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify break points    ###### MOVE????\n",
    "def is_breakpt(pts):\n",
    "    point1, point2 = pts.split('-')\n",
    "    if point2 == 'AD':\n",
    "        return 1\n",
    "    elif point1 != 'AD' and int(point2)> int(point1) and int(point2) == 40:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_player['BreakPt'] = df_player['Pts'].apply(is_breakpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Butterfly point cloud in 3d for TFiDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rals, wins = df_player['Shots1'], df_player['Winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, we could remove positional indications (+, -, =, ;, ^)\n",
    "rals = rals.map(lambda x: re.sub(r'([\\+\\-\\=\\;\\^])', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform rallies into one-hot vectors or TF-iDF vectors\n",
    "vect = TfidfVectorizer  # CountVectorizer\n",
    "vectorizer = vect(lowercase=False, analyzer='word', token_pattern='\\S+', max_df=1.0, min_df=100)\n",
    "X = vectorizer.fit_transform(rals).toarray()\n",
    "print('Vocabulary of length {}:\\n'.format(len(vectorizer.get_feature_names())), \n",
    "      vectorizer.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    XX = wins[labels == i]\n",
    "    print('Cluster {}: '.format(i), 'Population = {}'.format(len(XX)), '-- Win rate = {:.3f}'.format(XX.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect cluster\n",
    "rals[labels == 1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful library for interactive 3d plot\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d PCA projection\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "trace = go.Scatter3d(\n",
    "    x=X_pca[:,0], y=X_pca[:,1], z=X_pca[:,2],\n",
    "    mode='markers',\n",
    "    text=rals, #labels,             ######  REMOVE X,Z,Y, ADD RALS, LABELS, ETC. ALL TOGETHER..!!!\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color=wins,        # set color to an array/list of desired values\n",
    "#         color=kmeans.labels_,\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.5\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=[trace], layout=go.Layout(margin=dict(l=0,r=0,b=0,t=0)))\n",
    "py.offline.plot(fig, filename='3d-Shots1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA components \n",
    "features = vectorizer.get_feature_names()\n",
    "for i in range(pca.n_components_):\n",
    "    components_sorted = pd.Series(pca.components_[i],\n",
    "                                  index=features).sort_values(ascending=False)\n",
    "    print('PCA component {}: \\n'.format(i),\n",
    "          components_sorted[:2], '\\n', components_sorted[-2:])   ###### beautify!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impose some constraints on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select long rallies starting with '4'\n",
    "constraints = (df_player['Shots1'].str.startswith('4')) & (df_player['Shots1'].str.len() > 4)\n",
    "rals, wins = df_player[constraints]['Shots1'], df_player[constraints]['Winner']\n",
    "len(rals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform rallies into one-hot vectors or TF-iDF vectors\n",
    "vect = TfidfVectorizer  # CountVectorizer\n",
    "vectorizer = vect(lowercase=False, analyzer='word', token_pattern='\\S+', max_df=1.0, min_df=10)\n",
    "X = vectorizer.fit_transform(rals.apply(split_shots)).toarray()\n",
    "print('Vocabulary of length {}:\\n'.format(len(vectorizer.get_feature_names())), \n",
    "      vectorizer.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Could standardize features by removing the mean and scaling to unit variance\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    XX = wins[labels == i]\n",
    "    print('Cluster {}: '.format(i), 'Population = {}'.format(len(XX)), '-- Win rate = {:.3f}'.format(XX.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecrt cluster\n",
    "rals[labels == 2][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d plot\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "trace = go.Scatter3d(\n",
    "    x=X_pca[:,0], y=X_pca[:,1], z=X_pca[:,2],\n",
    "    mode='markers',\n",
    "    text=rals, #labels, \n",
    "    marker=dict(\n",
    "        size=6,\n",
    "#         color=wins,        # set color to an array/list\n",
    "        color=labels,\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.5\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=[trace], layout=go.Layout(margin=dict(l=0,r=0,b=0,t=0)))\n",
    "py.offline.plot(fig, filename='3d-Direction.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X_pca)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    XX = wins[labels == i]\n",
    "    print('Cluster {}: '.format(i), 'Population = {}'.format(len(XX)), '-- Win rate = {:.3f}'.format(XX.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Cluster 2 has high win rate, probably due to the presence of f+3 attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series for matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ids = df_player['match_id'].unique()\n",
    "len(match_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove matches with forfeits\n",
    "last_set_winner = []\n",
    "for i in range(len(match_ids)):    ###### USE GROUPBY!?\n",
    "    set_winner = df_player[df_player['match_id']==match_ids[i]]['SetW'].iloc[-1:].values[0]\n",
    "    last_set_winner.append(set_winner)\n",
    "match_ids = [match_ids[i] for i in range(len(match_ids)) if last_set_winner[i] != 0]\n",
    "len(match_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match winner: {0: player won match, 1: player lost match}\n",
    "match_winner = [df_player[df_player['match_id']==m_id]['Winner'].iloc[-1:].values[0] for m_id in match_ids]\n",
    "len(match_winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum (number of pts won - number of pts lost)\n",
    "def momentum(match):\n",
    "    Win = df_player[df_player['match_id']==match]['Winner'].replace(0,-1)\n",
    "    CumSum = Win.cumsum()\n",
    "    return CumSum.reset_index(drop=True).rename(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(momentum(match_ids[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(len(match_ids)):  ##### larger fig\n",
    "    colors = ['r', 'g']\n",
    "    plt.plot(momentum(match_ids[i]), c=colors[match_winner[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select momenta for beginning (first n_steps points) of tight matches (ending with abs(momentum) < bdry)\n",
    "n_steps = 200\n",
    "bdry = 10\n",
    "list_momenta = []\n",
    "list_win = []\n",
    "for i in range(len(match_ids)):\n",
    "    mom = momentum(match_ids[i])\n",
    "    if len(mom) > n_steps and -bdry < mom.iloc[-1] < bdry:\n",
    "        list_momenta.append(mom[:n_steps])\n",
    "        list_win.append(match_winner[i])\n",
    "df_momenta = pd.concat(list_momenta, axis=1).T\n",
    "print('Number of matches selected:', len(list_momenta))\n",
    "df_momenta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(list_momenta)):\n",
    "    plt.plot(df_momenta.iloc[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hierarchical clustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "Z = linkage(df_momenta, 'ward')\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "dn = dendrogram(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(df_momenta, method='complete', metric='correlation')\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "dn = dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# Plot k clusters from linkage matrix Z\n",
    "def plot_clusters(df, Z, k, plot=False):        ###### CHECK, REWRITE!!\n",
    "    fc = fcluster(Z, k, criterion='maxclust')\n",
    "    s = pd.Series(fc)\n",
    "    clusters = s.unique()\n",
    "\n",
    "    for cluster in clusters:\n",
    "        cluster_indices = s[s==cluster].index\n",
    "        print('Cluster {} ({} members):'.format(cluster, len(cluster_indices)))    ##### PRINT WIN RATE!!!\n",
    "        if plot:\n",
    "            colors = ['r', 'g']\n",
    "            df.T.iloc[:,cluster_indices].plot(legend=None, color=[colors[list_win[i]] for i in cluster_indices])\n",
    "            plt.ylim(-15, 15)\n",
    "            plt.show()\n",
    "            \n",
    "plot_clusters(df_momenta, Z, 4, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(list_win)/len(list_win)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "There are clusters with high winning rate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series for tournament / career\n",
    "\n",
    "Plot statistics like 1st/2nd serve rate, number of winner shots, forced/unforced error, aces, forehands/backhands, directions, positions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match statistics\n",
    "\n",
    "Aces\n",
    "\n",
    "Double Faults\n",
    "\n",
    "1st Serve In %\n",
    "\n",
    "1st Serve Points Won\n",
    "\n",
    "2nd Serve Points Won\n",
    "\n",
    "Service Points Won\n",
    "\n",
    "Total Points Won\n",
    "\n",
    "Break Points Won\n",
    "\n",
    "\n",
    "\n",
    "Winners\n",
    "\n",
    "Unforced Errors\n",
    "\n",
    "Net Points Won\n",
    "\n",
    "\n",
    "Overall\n",
    "\n",
    "\n",
    "Points Won, 0-4 Shots\n",
    "\n",
    "Points Won, 5-9 Shots\n",
    "\n",
    "Points Won, 10+ Shots\n",
    "\n",
    "\n",
    "Most Consec Pts Won\n",
    "\n",
    "Last Ten Points\n",
    "\n",
    "Longest rally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUPBY APPROACH..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance between 1st and 2nd serves... aces vs double faults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning\n",
    "\n",
    "Create a world-model on say Nadal, then train an RL agent to find the optimal strategy. \n",
    "\n",
    "How to ensure that the agent won't systematically recommend impossible shots (volleys on returns, net shots...)????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select games of 'player' against 'opponent'\n",
    "opponent_name = 'Rafael_Nadal'\n",
    "df_po = df_player[(df_player['Player1'] == opponent_name) | (df_player['Player2'] == opponent_name)]  \n",
    "print(len(df_po))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_po.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build 3-grams of sequential shots for player (p) and opponent (o)  \n",
    "\n",
    "from nltk import ngrams\n",
    "\n",
    "shots_opo = []\n",
    "\n",
    "for i in range(len(df_po)):\n",
    "    shots = df_po['Shots'].iloc[i]\n",
    "    length = len(shots.split())\n",
    "    server = df_po['Server'].iloc[i]\n",
    "    \n",
    "    if server == 1: \n",
    "        if length%2==0:\n",
    "            z = '' \n",
    "        else:\n",
    "            z = ' '\n",
    "        # 'X' for waiting to receive serve\n",
    "        sentence = 'X ' + df_po['Shots'].iloc[i] + z + df_po['Outcome'].iloc[i]\n",
    "        n_grams = list(ngrams(sentence.split(), 3))\n",
    "        shots_opo.extend(n_grams[0::2])\n",
    "        \n",
    "    if server == 0: \n",
    "        if length%2==0:\n",
    "            z = ' ' \n",
    "        else:\n",
    "            z = ''\n",
    "        # 'X' for waiting to receive serve\n",
    "        sentence = 'X ' + df_po['Shots'].iloc[i] + z + df_po['Outcome'].iloc[i]\n",
    "        n_grams = list(ngrams(sentence.split(), 3))\n",
    "        shots_opo.extend(n_grams[1::2])\n",
    "        \n",
    "print('OPO: {}'.format(len(shots_opo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_opo[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible states (omit rare shots)\n",
    "from collections import Counter\n",
    "\n",
    "states_counts = Counter(list(sum(shots_opo, ()))).most_common(100)\n",
    "states = [state[0] for state in states_counts]\n",
    "print('{} possible states:\\n'.format(len(states)), states) \n",
    "\n",
    "# Remove triples containing uncommon shots\n",
    "shots_opo_com = [x for x in shots_opo if x[0] in states and x[1] in states and x[2] in states]  #### BEAUTIFY! INTERSECTION.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible actions (omit rare shots)\n",
    "vectorizer = CountVectorizer(lowercase=False, analyzer='word', token_pattern='\\S+', \n",
    "                             max_df=1.0, min_df=100)\n",
    "vectorizer.fit('X ' + df_po['Shots'])\n",
    "actions = vectorizer.get_feature_names()\n",
    "print('{} possible actions:\\n'.format(len(actions)), actions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model based on opponent's style\n",
    "# Given current state s_t and action a_t, return next state s_t+1\n",
    "def model(state, action):\n",
    "    n_grams_sa = [n_gram for n_gram in shots_opo_com if n_gram[0]==state and n_gram[1]==action]\n",
    "    if(len(n_grams_sa) > 1):    # exclude rare reactions\n",
    "        return np.random.choice([n_gram[2] for n_gram in n_grams_sa])\n",
    "    return 'n@'   # when (s,a) never happened, return unforced error in net\n",
    "\n",
    "# Example\n",
    "model('5', 'f28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether a state is win (1), lose (0), or neither (-1)\n",
    "def is_win(state):\n",
    "    if state == '*':\n",
    "        return 1\n",
    "    elif '*' in state:\n",
    "        return 0\n",
    "    if state[0] in ['n','w','d','x','g','e','!','#','@']:\n",
    "        return 0\n",
    "    elif state[-1] in ['n','w','d','x','g','e','!','#','@']:\n",
    "        return 1\n",
    "    return -1   # neither won nor lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn to serve against the AI tennis opponent!\n",
    "\n",
    "current_state = 'X'\n",
    "while True:       ###### CAREFUL WHEN INTERRUPTING\n",
    "    shot = input()\n",
    "    next_state = model(current_state, shot)\n",
    "    print(next_state)\n",
    "    current_state = next_state\n",
    "    if is_win(next_state) == 1:\n",
    "        print('Winner!')\n",
    "        break\n",
    "    if is_win(next_state) == 0:\n",
    "        print('Loser!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-learning algorithm\n",
    "\n",
    "The purpose of the Q-learning algorithm is to obtain the quality function **Q(state,action)**. This function will be used to obtain the optimal policy **p(s)=argmax_a(Q(s,a))**: the policy defines the agent's behaviour. Indeed, given a state s at which the agent is found, **p(s)** corresponds to the best action the agent could perform from that state. \n",
    "\n",
    "The Q-learning algorithm finds the quality function **Q(s,a)** by *exploring* the state-action space: in our case, our agent plays tennis at random and gets rewarded depending on the future outcome of the point played. \n",
    "\n",
    "The Q-function update is given by the following formula:\n",
    "\n",
    "**Q(s,a)   <---   (1-alpha) Q(s,a) + alpha [r(s,s') + gamma * max_a Q(s',a)],**\n",
    "\n",
    "where **gamma** is the discount factor and **alpha** is the learning parameter. These hyperparameters are to be chosen empirically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward function r(s,s')\n",
    "def reward(current_state, next_state):\n",
    "    if is_win(current_state) == 1:   ###### SUSPICIOUS?!?!  NEVER USED!??!\n",
    "        return 10\n",
    "    if is_win(current_state) == 0:\n",
    "        return -10\n",
    "    if is_win(next_state) == 1:\n",
    "        return 20\n",
    "    if is_win(next_state) == 0:\n",
    "        return -20\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward('f3', 'b1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_opo_com[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Q-matrix\n",
    "n_episodes = 20000\n",
    "Q = np.zeros((len(states),len(actions)))   ###### RANDOM INITIALIZATION??\n",
    "\n",
    "# Policy function\n",
    "def policy(state):\n",
    "    row = Q[states.index(state),:]\n",
    "    argmaxi = np.argmax(row)\n",
    "    return actions[argmaxi]\n",
    "\n",
    "# Initialize maxima of Q over all possible actions, given the current state\n",
    "maxima = [0] * len(states)\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.3   # learning rate\n",
    "gamma = 0.1   # discount factor\n",
    "epsilon = 0.1   # for epsilon-greedy policy\n",
    "\n",
    "serves_opponent = [shot for shot in [sh[0] for sh in shots_opo_com] if shot[0] in '456']\n",
    "\n",
    "# Exploration procedure\n",
    "print('Episode number:')\n",
    "for episode in range(n_episodes):\n",
    "    print( episode, end='\\r')\n",
    "    # Random choice of server\n",
    "    if np.random.randint(0,2) == 1:\n",
    "        current_state = 'X'\n",
    "    else:\n",
    "        current_state = np.random.choice(serves_opponent)\n",
    "    # Play shot by shot\n",
    "    for step in range(100):       ##### WHILE TRUE???\n",
    "        if np.random.random() < epsilon:   # Exploration in epsilon % of cases\n",
    "            action = np.random.choice(actions)\n",
    "        else:\n",
    "            action = policy(current_state)\n",
    "        next_state = model(current_state, action)   # Get opponent's reaction\n",
    "        # Update Q        \n",
    "        s = states.index(current_state)\n",
    "        a = actions.index(action)\n",
    "        r = reward(current_state, next_state)\n",
    "        max_aQ = maxima[states.index(next_state)]\n",
    "        Q[s,a] = (1 - alpha)*Q[s,a] + alpha*(r + gamma*max_aQ)\n",
    "        maxima[s] = max(maxima[s], Q[s,a])\n",
    "        current_state = next_state\n",
    "        if is_win(current_state) == 1:\n",
    "            break\n",
    "        if is_win(current_state) == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained Q-matrix\n",
    "# Q_trained = Q.copy()\n",
    "# np.save('RL_trained_Q2',Q_trained)\n",
    "plt.hist(Q[states.index('f3'),:],20)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Q-matrix\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(20,20))\n",
    "a=sns.heatmap(Q)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('state: ', states[23],'action: ',actions[19])\n",
    "print('state: ', states[35],'action: ',actions[20])\n",
    "print('state: ', states[41],'action: ',actions[36])\n",
    "print('state: ', states[76],'action: ',actions[38])\n",
    "print('state: ', states[48],'action: ',actions[38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized RF plays against historical RN !!\n",
    "points_won = 0\n",
    "points_lost = 0\n",
    "\n",
    "for num in range(5000):\n",
    "    print(num, end='\\r')\n",
    "    #random choice on who is serving\n",
    "    if np.random.randint(0,2) == 0 :\n",
    "        current_state = 'X'\n",
    "    else :\n",
    "        current_state = np.random.choice(serves_opponent)\n",
    "    for n in range(100):\n",
    "        shot = policy(current_state)\n",
    "        next_state = model(current_state,shot)\n",
    "        reward(current_state,next_state)\n",
    "        #print('to ', shot, 'RN replied with: ', current_state )\n",
    "        current_state = next_state\n",
    "        if is_win(current_state) == 1:\n",
    "            points_won += 1\n",
    "            break\n",
    "        if is_win(current_state) == 0:\n",
    "            points_lost += 1\n",
    "            break\n",
    "            \n",
    "print('How well are we performing? ', points_won/(points_lost+points_won))\n",
    "print('Baseline performance: ',1-(df_po['Winner'].sum()/len(df_po['Winner'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
